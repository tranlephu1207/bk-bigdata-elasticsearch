{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network-Aware User Profile Search with Elasticsearch\n",
    "\n",
    "This notebook builds a search system that ranks users based on:\n",
    "1. **Profile matching** - Traditional keyword relevance\n",
    "2. **Social distance** - How many hops away in the network\n",
    "3. **Mutual friends** - Number of shared connections\n",
    "4. **Community membership** - Shared circles/communities\n",
    "\n",
    "## Setup Requirements\n",
    "\n",
    "```bash\n",
    "# Install Elasticsearch on macOS\n",
    "brew install elasticsearch\n",
    "brew services start elasticsearch\n",
    "\n",
    "# Install required Python packages\n",
    "pip install elasticsearch networkx pandas numpy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch in /Users/phutran/miniconda3/lib/python3.8/site-packages (8.19.2)\n",
      "Requirement already satisfied: networkx in /Users/phutran/miniconda3/lib/python3.8/site-packages (3.1)\n",
      "Requirement already satisfied: pandas in /Users/phutran/miniconda3/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in /Users/phutran/miniconda3/lib/python3.8/site-packages (1.24.4)\n",
      "Requirement already satisfied: typing-extensions in /Users/phutran/miniconda3/lib/python3.8/site-packages (from elasticsearch) (4.13.2)\n",
      "Requirement already satisfied: python-dateutil in /Users/phutran/miniconda3/lib/python3.8/site-packages (from elasticsearch) (2.9.0.post0)\n",
      "Requirement already satisfied: elastic-transport<9,>=8.15.1 in /Users/phutran/miniconda3/lib/python3.8/site-packages (from elasticsearch) (8.17.1)\n",
      "Requirement already satisfied: certifi in /Users/phutran/miniconda3/lib/python3.8/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in /Users/phutran/miniconda3/lib/python3.8/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (1.26.6)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/phutran/miniconda3/lib/python3.8/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/phutran/miniconda3/lib/python3.8/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/phutran/miniconda3/lib/python3.8/site-packages (from python-dateutil->elasticsearch) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install elasticsearch networkx pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from collections import defaultdict, Counter\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download and Extract Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already downloaded\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "url = \"https://snap.stanford.edu/data/facebook.tar.gz\"\n",
    "data_dir = Path(\"./facebook_data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "tar_path = data_dir / \"facebook.tar.gz\"\n",
    "\n",
    "if not tar_path.exists():\n",
    "    print(\"Downloading dataset...\")\n",
    "    urllib.request.urlretrieve(url, tar_path)\n",
    "    print(\"Download complete!\")\n",
    "    \n",
    "    # Extract\n",
    "    print(\"Extracting...\")\n",
    "    with tarfile.open(tar_path, 'r:gz') as tar:\n",
    "        tar.extractall(data_dir)\n",
    "    print(\"Extraction complete!\")\n",
    "else:\n",
    "    print(\"Dataset already downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Explore Dataset Structure\n",
    "\n",
    "The Facebook dataset contains:\n",
    "- `.edges` - Edge lists (friendships)\n",
    "- `.feat` - Feature vectors for each user\n",
    "- `.featnames` - Feature names\n",
    "- `.circles` - Friend circles (communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 ego networks\n",
      "Ego users: ['686', '348', '3437', '1912', '1684', '0', '698', '3980', '414', '107']\n"
     ]
    }
   ],
   "source": [
    "# Find all ego networks in the dataset\n",
    "facebook_dir = data_dir / \"facebook\"\n",
    "ego_users = []\n",
    "\n",
    "for file in facebook_dir.glob(\"*.edges\"):\n",
    "    ego_id = file.stem\n",
    "    ego_users.append(ego_id)\n",
    "\n",
    "print(f\"Found {len(ego_users)} ego networks\")\n",
    "print(f\"Ego users: {ego_users}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load and Process Network Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network for user 686...\n",
      "Loading network for user 348...\n",
      "Loading network for user 3437...\n",
      "Loading network for user 1912...\n",
      "Loading network for user 1684...\n",
      "Loading network for user 0...\n",
      "Loading network for user 698...\n",
      "Loading network for user 3980...\n",
      "Loading network for user 414...\n",
      "Loading network for user 107...\n",
      "\n",
      "Total nodes: 3963\n",
      "Total edges: 105082\n",
      "Users with features: 4039\n"
     ]
    }
   ],
   "source": [
    "class FacebookNetworkProcessor:\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.G = nx.Graph()\n",
    "        self.user_features = {}\n",
    "        self.user_circles = defaultdict(list)\n",
    "        self.feature_names = []\n",
    "        \n",
    "    def load_network(self, ego_id):\n",
    "        \"\"\"Load ego network for a specific user\"\"\"\n",
    "        edges_file = self.data_dir / f\"{ego_id}.edges\"\n",
    "        feat_file = self.data_dir / f\"{ego_id}.feat\"\n",
    "        featnames_file = self.data_dir / f\"{ego_id}.featnames\"\n",
    "        circles_file = self.data_dir / f\"{ego_id}.circles\"\n",
    "        \n",
    "        # Load edges\n",
    "        if edges_file.exists():\n",
    "            with open(edges_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    u, v = line.strip().split()\n",
    "                    self.G.add_edge(int(u), int(v))\n",
    "        \n",
    "        # Add ego node and connect to all nodes in their network\n",
    "        ego_id_int = int(ego_id)\n",
    "        for node in list(self.G.nodes()):\n",
    "            if node != ego_id_int:\n",
    "                self.G.add_edge(ego_id_int, node)\n",
    "        \n",
    "        # Load feature names\n",
    "        if featnames_file.exists():\n",
    "            with open(featnames_file, 'r') as f:\n",
    "                self.feature_names = [line.strip().split(' ', 1) for line in f]\n",
    "        \n",
    "        # Load features\n",
    "        if feat_file.exists():\n",
    "            with open(feat_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    user_id = int(parts[0])\n",
    "                    features = [int(x) for x in parts[1:]]\n",
    "                    self.user_features[user_id] = features\n",
    "        \n",
    "        # Add ego features (usually all 0s)\n",
    "        if self.feature_names:\n",
    "            self.user_features[ego_id_int] = [0] * len(self.feature_names)\n",
    "        \n",
    "        # Load circles\n",
    "        if circles_file.exists():\n",
    "            with open(circles_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    circle_name = parts[0]\n",
    "                    members = [int(x) for x in parts[1:]]\n",
    "                    for member in members:\n",
    "                        self.user_circles[member].append(circle_name)\n",
    "    \n",
    "    def load_all_networks(self):\n",
    "        \"\"\"Load all ego networks and combine them\"\"\"\n",
    "        for file in self.data_dir.glob(\"*.edges\"):\n",
    "            ego_id = file.stem\n",
    "            print(f\"Loading network for user {ego_id}...\")\n",
    "            self.load_network(ego_id)\n",
    "        \n",
    "        print(f\"\\nTotal nodes: {self.G.number_of_nodes()}\")\n",
    "        print(f\"Total edges: {self.G.number_of_edges()}\")\n",
    "        print(f\"Users with features: {len(self.user_features)}\")\n",
    "    \n",
    "    def compute_network_features(self, user_id, reference_user_id):\n",
    "        \"\"\"Compute network-based features between two users\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        if user_id not in self.G or reference_user_id not in self.G:\n",
    "            return {\n",
    "                'social_distance': 999,\n",
    "                'mutual_friends': 0,\n",
    "                'shared_circles': 0\n",
    "            }\n",
    "        \n",
    "        # Social distance (shortest path)\n",
    "        try:\n",
    "            features['social_distance'] = nx.shortest_path_length(\n",
    "                self.G, user_id, reference_user_id\n",
    "            )\n",
    "        except nx.NetworkXNoPath:\n",
    "            features['social_distance'] = 999  # Not connected\n",
    "        \n",
    "        # Mutual friends\n",
    "        user_friends = set(self.G.neighbors(user_id))\n",
    "        ref_friends = set(self.G.neighbors(reference_user_id))\n",
    "        features['mutual_friends'] = len(user_friends & ref_friends)\n",
    "        \n",
    "        # Shared circles\n",
    "        user_circles = set(self.user_circles.get(user_id, []))\n",
    "        ref_circles = set(self.user_circles.get(reference_user_id, []))\n",
    "        features['shared_circles'] = len(user_circles & ref_circles)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def create_user_profile(self, user_id):\n",
    "        \"\"\"Create a searchable profile for a user\"\"\"\n",
    "        profile = {\n",
    "            'user_id': user_id,\n",
    "            'degree': self.G.degree(user_id) if user_id in self.G else 0,\n",
    "            'circles': self.user_circles.get(user_id, []),\n",
    "        }\n",
    "        \n",
    "        # Convert features to named attributes\n",
    "        if user_id in self.user_features and self.feature_names:\n",
    "            features = self.user_features[user_id]\n",
    "            profile['attributes'] = []\n",
    "            \n",
    "            for i, (feat_id, feat_name) in enumerate(self.feature_names):\n",
    "                if i < len(features) and features[i] == 1:\n",
    "                    profile['attributes'].append(feat_name)\n",
    "        \n",
    "        return profile\n",
    "\n",
    "# Initialize processor\n",
    "processor = FacebookNetworkProcessor(facebook_dir)\n",
    "processor.load_all_networks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Setup Elasticsearch Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull the Elasticsearch image (ARM64 compatible)\n",
    "docker pull docker.elastic.co/elasticsearch/elasticsearch:8.11.0\n",
    "\n",
    "# Run Elasticsearch container\n",
    "docker run -d \\\n",
    "  --name elasticsearch \\\n",
    "  -p 9200:9200 \\\n",
    "  -p 9300:9300 \\\n",
    "  -e \"discovery.type=single-node\" \\\n",
    "  -e \"xpack.security.enabled=false\" \\\n",
    "  -e \"xpack.security.http.ssl.enabled=false\" \\\n",
    "  -e \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" \\\n",
    "  docker.elastic.co/elasticsearch/elasticsearch:8.11.0\n",
    "  \n",
    "# Check if container is running\n",
    "docker ps\n",
    "\n",
    "# Test connection\n",
    "curl http://localhost:9200\n",
    "\n",
    "# You should see JSON output with cluster info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Connected to Elasticsearch\n",
      "Cluster info: 8.11.0\n"
     ]
    }
   ],
   "source": [
    "# Connect to Elasticsearch\n",
    "es = Elasticsearch(\n",
    "    ['http://localhost:9200'],\n",
    "    basic_auth=None  # Add auth if needed\n",
    ")\n",
    "\n",
    "# Check connection\n",
    "if es.ping():\n",
    "    print(\"✓ Connected to Elasticsearch\")\n",
    "    print(f\"Cluster info: {es.info()['version']['number']}\")\n",
    "else:\n",
    "    print(\"✗ Could not connect to Elasticsearch\")\n",
    "    print(\"Make sure Elasticsearch is running: brew services start elasticsearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Index with Custom Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing index: facebook_users\n",
      "✓ Created index: facebook_users\n"
     ]
    }
   ],
   "source": [
    "index_name = \"facebook_users\"\n",
    "\n",
    "# Delete index if it exists\n",
    "if es.indices.exists(index=index_name):\n",
    "    es.indices.delete(index=index_name)\n",
    "    print(f\"Deleted existing index: {index_name}\")\n",
    "\n",
    "# Create index with mapping\n",
    "index_mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"user_id\": {\"type\": \"integer\"},\n",
    "            \"degree\": {\"type\": \"integer\"},\n",
    "            \"circles\": {\n",
    "                \"type\": \"text\",\n",
    "                \"fields\": {\n",
    "                    \"keyword\": {\"type\": \"keyword\"}\n",
    "                }\n",
    "            },\n",
    "            \"attributes\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"standard\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    }\n",
    "}\n",
    "\n",
    "es.indices.create(index=index_name, body=index_mapping)\n",
    "print(f\"✓ Created index: {index_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Index User Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing users...\n",
      "✓ Indexed 3963 users\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'_shards': {'total': 1, 'successful': 1, 'failed': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_docs():\n",
    "    \"\"\"Generator for bulk indexing\"\"\"\n",
    "    for user_id in processor.G.nodes():\n",
    "        profile = processor.create_user_profile(user_id)\n",
    "        yield {\n",
    "            \"_index\": index_name,\n",
    "            \"_id\": user_id,\n",
    "            \"_source\": profile\n",
    "        }\n",
    "\n",
    "# Bulk index\n",
    "print(\"Indexing users...\")\n",
    "success, failed = helpers.bulk(es, generate_docs(), stats_only=True)\n",
    "print(f\"✓ Indexed {success} users\")\n",
    "if failed:\n",
    "    print(f\"✗ Failed: {failed}\")\n",
    "\n",
    "# Refresh index\n",
    "es.indices.refresh(index=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Implement Network-Aware Search\n",
    "\n",
    "This is where the magic happens! We'll create a custom scoring function that combines:\n",
    "- Text relevance (Elasticsearch BM25)\n",
    "- Social distance (exponential decay)\n",
    "- Mutual friends (linear boost)\n",
    "- Shared circles (category boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Network-aware search engine ready!\n"
     ]
    }
   ],
   "source": [
    "class NetworkAwareSearch:\n",
    "    def __init__(self, es_client, processor, index_name):\n",
    "        self.es = es_client\n",
    "        self.processor = processor\n",
    "        self.index = index_name\n",
    "    \n",
    "    def search(self, query, searcher_id, size=10, weights=None):\n",
    "        \"\"\"\n",
    "        Perform network-aware search.\n",
    "        \n",
    "        Args:\n",
    "            query: Search query string\n",
    "            searcher_id: User performing the search\n",
    "            size: Number of results to return\n",
    "            weights: Dict with keys: text, distance, mutual, circles\n",
    "        \"\"\"\n",
    "        if weights is None:\n",
    "            weights = {\n",
    "                'text': 1.0,\n",
    "                'distance': 0.5,\n",
    "                'mutual': 0.3,\n",
    "                'circles': 0.2\n",
    "            }\n",
    "        \n",
    "        # Step 1: Get candidate results from Elasticsearch\n",
    "        es_query = {\n",
    "            \"query\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"attributes^2\", \"circles\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            },\n",
    "            \"size\": size * 3  # Get more candidates for reranking\n",
    "        }\n",
    "        \n",
    "        response = self.es.search(index=self.index, body=es_query)\n",
    "        \n",
    "        # Step 2: Rerank with network features\n",
    "        results = []\n",
    "        for hit in response['hits']['hits']:\n",
    "            user_id = hit['_source']['user_id']\n",
    "            text_score = hit['_score']\n",
    "            \n",
    "            # Compute network features\n",
    "            net_features = self.processor.compute_network_features(\n",
    "                user_id, searcher_id\n",
    "            )\n",
    "            \n",
    "            # Compute network score components\n",
    "            distance_score = self._distance_score(net_features['social_distance'])\n",
    "            mutual_score = self._mutual_score(net_features['mutual_friends'])\n",
    "            circle_score = self._circle_score(net_features['shared_circles'])\n",
    "            \n",
    "            # Combined score\n",
    "            final_score = (\n",
    "                weights['text'] * text_score +\n",
    "                weights['distance'] * distance_score +\n",
    "                weights['mutual'] * mutual_score +\n",
    "                weights['circles'] * circle_score\n",
    "            )\n",
    "            \n",
    "            results.append({\n",
    "                'user_id': user_id,\n",
    "                'profile': hit['_source'],\n",
    "                'scores': {\n",
    "                    'final': final_score,\n",
    "                    'text': text_score,\n",
    "                    'distance': distance_score,\n",
    "                    'mutual': mutual_score,\n",
    "                    'circles': circle_score\n",
    "                },\n",
    "                'network': net_features\n",
    "            })\n",
    "        \n",
    "        # Sort by final score\n",
    "        results.sort(key=lambda x: x['scores']['final'], reverse=True)\n",
    "        \n",
    "        return results[:size]\n",
    "    \n",
    "    def _distance_score(self, distance):\n",
    "        \"\"\"Exponential decay based on social distance\"\"\"\n",
    "        if distance >= 999:\n",
    "            return 0.0\n",
    "        return np.exp(-0.5 * distance) * 10\n",
    "    \n",
    "    def _mutual_score(self, mutual_friends):\n",
    "        \"\"\"Linear score for mutual friends\"\"\"\n",
    "        return min(mutual_friends, 20) * 0.5\n",
    "    \n",
    "    def _circle_score(self, shared_circles):\n",
    "        \"\"\"Score for shared community membership\"\"\"\n",
    "        return shared_circles * 2.0\n",
    "    \n",
    "    def compare_with_baseline(self, query, searcher_id, size=10):\n",
    "        \"\"\"Compare network-aware vs baseline search\"\"\"\n",
    "        # Baseline: text-only\n",
    "        baseline_query = {\n",
    "            \"query\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"attributes^2\", \"circles\"]\n",
    "                }\n",
    "            },\n",
    "            \"size\": size\n",
    "        }\n",
    "        \n",
    "        baseline_response = self.es.search(index=self.index, body=baseline_query)\n",
    "        baseline_results = [\n",
    "            {\n",
    "                'user_id': hit['_source']['user_id'],\n",
    "                'score': hit['_score']\n",
    "            }\n",
    "            for hit in baseline_response['hits']['hits']\n",
    "        ]\n",
    "        \n",
    "        # Network-aware\n",
    "        network_results = self.search(query, searcher_id, size)\n",
    "        \n",
    "        return {\n",
    "            'baseline': baseline_results,\n",
    "            'network_aware': network_results,\n",
    "            'query': query,\n",
    "            'searcher_id': searcher_id\n",
    "        }\n",
    "\n",
    "# Initialize search engine\n",
    "search_engine = NetworkAwareSearch(es, processor, index_name)\n",
    "print(\"✓ Network-aware search engine ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Test the Search System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching as user: 686\n",
      "User has 176 friends\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a searcher (ego user)\n",
    "if ego_users:\n",
    "    searcher_id = int(ego_users[0])\n",
    "else:\n",
    "    searcher_id = list(processor.G.nodes())[0]\n",
    "\n",
    "print(f\"Searching as user: {searcher_id}\")\n",
    "print(f\"User has {processor.G.degree(searcher_id)} friends\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'education work'\n",
      "\n",
      "================================================================================\n",
      "\n",
      "1. User 1085\n",
      "   Final Score: 9.770\n",
      "   └─ Text: 6.731 | Distance: 3.679 | Mutual: 4.000 | Circles: 0.000\n",
      "   Network:\n",
      "   └─ Social distance: 2 hops\n",
      "   └─ Mutual friends: 8\n",
      "   └─ Shared circles: 0\n",
      "   Profile:\n",
      "   └─ Degree: 72 friends\n",
      "   └─ Circles: circle3, circle4, circle19\n",
      "\n",
      "2. User 2107\n",
      "   Final Score: 9.611\n",
      "   └─ Text: 6.722 | Distance: 3.679 | Mutual: 3.500 | Circles: 0.000\n",
      "   Network:\n",
      "   └─ Social distance: 2 hops\n",
      "   └─ Mutual friends: 7\n",
      "   └─ Shared circles: 0\n",
      "   Profile:\n",
      "   └─ Degree: 43 friends\n",
      "\n",
      "3. User 1779\n",
      "   Final Score: 8.848\n",
      "   └─ Text: 6.858 | Distance: 3.679 | Mutual: 0.500 | Circles: 0.000\n",
      "   Network:\n",
      "   └─ Social distance: 2 hops\n",
      "   └─ Mutual friends: 1\n",
      "   └─ Shared circles: 0\n",
      "   Profile:\n",
      "   └─ Degree: 22 friends\n",
      "   └─ Circles: circle6\n",
      "\n",
      "4. User 909\n",
      "   Final Score: 8.822\n",
      "   └─ Text: 6.832 | Distance: 3.679 | Mutual: 0.500 | Circles: 0.000\n",
      "   Network:\n",
      "   └─ Social distance: 2 hops\n",
      "   └─ Mutual friends: 1\n",
      "   └─ Shared circles: 0\n",
      "   Profile:\n",
      "   └─ Degree: 12 friends\n",
      "\n",
      "5. User 992\n",
      "   Final Score: 8.779\n",
      "   └─ Text: 6.789 | Distance: 3.679 | Mutual: 0.500 | Circles: 0.000\n",
      "   Network:\n",
      "   └─ Social distance: 2 hops\n",
      "   └─ Mutual friends: 1\n",
      "   └─ Shared circles: 0\n",
      "   Profile:\n",
      "   └─ Degree: 31 friends\n",
      "   └─ Circles: circle8\n"
     ]
    }
   ],
   "source": [
    "# Example search\n",
    "query = \"education work\"  # Adjust based on available features\n",
    "\n",
    "results = search_engine.search(query, searcher_id, size=5)\n",
    "\n",
    "print(f\"Query: '{query}'\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"\\n{i}. User {result['user_id']}\")\n",
    "    print(f\"   Final Score: {result['scores']['final']:.3f}\")\n",
    "    print(f\"   └─ Text: {result['scores']['text']:.3f} | \"\n",
    "          f\"Distance: {result['scores']['distance']:.3f} | \"\n",
    "          f\"Mutual: {result['scores']['mutual']:.3f} | \"\n",
    "          f\"Circles: {result['scores']['circles']:.3f}\")\n",
    "    print(f\"   Network:\")\n",
    "    print(f\"   └─ Social distance: {result['network']['social_distance']} hops\")\n",
    "    print(f\"   └─ Mutual friends: {result['network']['mutual_friends']}\")\n",
    "    print(f\"   └─ Shared circles: {result['network']['shared_circles']}\")\n",
    "    print(f\"   Profile:\")\n",
    "    print(f\"   └─ Degree: {result['profile']['degree']} friends\")\n",
    "    if result['profile'].get('circles'):\n",
    "        print(f\"   └─ Circles: {', '.join(result['profile']['circles'][:3])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Compare with Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE SEARCH (text-only):\n",
      "==================================================\n",
      "1. User 1779 - Score: 6.858\n",
      "2. User 909 - Score: 6.832\n",
      "3. User 992 - Score: 6.789\n",
      "4. User 963 - Score: 6.770\n",
      "5. User 1845 - Score: 6.760\n",
      "\n",
      "\n",
      "NETWORK-AWARE SEARCH:\n",
      "==================================================\n",
      "1. User 1085 - Score: 9.770\n",
      "   └─ 2 hops, 8 mutual friends\n",
      "2. User 2107 - Score: 9.611\n",
      "   └─ 2 hops, 7 mutual friends\n",
      "3. User 1779 - Score: 8.848\n",
      "   └─ 2 hops, 1 mutual friends\n",
      "4. User 909 - Score: 8.822\n",
      "   └─ 2 hops, 1 mutual friends\n",
      "5. User 992 - Score: 8.779\n",
      "   └─ 2 hops, 1 mutual friends\n"
     ]
    }
   ],
   "source": [
    "comparison = search_engine.compare_with_baseline(query, searcher_id, size=5)\n",
    "\n",
    "print(\"BASELINE SEARCH (text-only):\")\n",
    "print(\"=\"*50)\n",
    "for i, result in enumerate(comparison['baseline'], 1):\n",
    "    print(f\"{i}. User {result['user_id']} - Score: {result['score']:.3f}\")\n",
    "\n",
    "print(\"\\n\\nNETWORK-AWARE SEARCH:\")\n",
    "print(\"=\"*50)\n",
    "for i, result in enumerate(comparison['network_aware'], 1):\n",
    "    print(f\"{i}. User {result['user_id']} - Score: {result['scores']['final']:.3f}\")\n",
    "    print(f\"   └─ {result['network']['social_distance']} hops, \"\n",
    "          f\"{result['network']['mutual_friends']} mutual friends\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Experiment with Different Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEXT-FOCUSED Configuration\n",
      "============================================================\n",
      "\n",
      "1. User 1779 - Score: 7.276\n",
      "   Distance: 2 hops, Mutual: 1\n",
      "\n",
      "2. User 909 - Score: 7.250\n",
      "   Distance: 2 hops, Mutual: 1\n",
      "\n",
      "3. User 992 - Score: 7.207\n",
      "   Distance: 2 hops, Mutual: 1\n",
      "\n",
      "============================================================\n",
      "NETWORK-FOCUSED Configuration\n",
      "============================================================\n",
      "\n",
      "1. User 1779 - Score: 4.147\n",
      "   Distance: 2 hops, Mutual: 1\n",
      "\n",
      "2. User 909 - Score: 4.139\n",
      "   Distance: 2 hops, Mutual: 1\n",
      "\n",
      "3. User 992 - Score: 4.126\n",
      "   Distance: 2 hops, Mutual: 1\n",
      "\n",
      "============================================================\n",
      "BALANCED Configuration\n",
      "============================================================\n",
      "\n",
      "1. User 1779 - Score: 4.683\n",
      "   Distance: 2 hops, Mutual: 1\n",
      "\n",
      "2. User 909 - Score: 4.670\n",
      "   Distance: 2 hops, Mutual: 1\n",
      "\n",
      "3. User 992 - Score: 4.648\n",
      "   Distance: 2 hops, Mutual: 1\n"
     ]
    }
   ],
   "source": [
    "# Try different weight configurations\n",
    "weight_configs = [\n",
    "    {'name': 'Text-focused', 'weights': {'text': 1.0, 'distance': 0.1, 'mutual': 0.1, 'circles': 0.1}},\n",
    "    {'name': 'Network-focused', 'weights': {'text': 0.3, 'distance': 0.5, 'mutual': 0.5, 'circles': 0.3}},\n",
    "    {'name': 'Balanced', 'weights': {'text': 0.5, 'distance': 0.3, 'mutual': 0.3, 'circles': 0.2}},\n",
    "]\n",
    "\n",
    "query = \"work education\"  # Adjust as needed\n",
    "\n",
    "for config in weight_configs:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{config['name'].upper()} Configuration\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    results = search_engine.search(\n",
    "        query, searcher_id, size=3, weights=config['weights']\n",
    "    )\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"\\n{i}. User {result['user_id']} - Score: {result['scores']['final']:.3f}\")\n",
    "        print(f\"   Distance: {result['network']['social_distance']} hops, \"\n",
    "              f\"Mutual: {result['network']['mutual_friends']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Analyze Network Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Statistics:\n",
      "==================================================\n",
      "Total users: 3963\n",
      "Total friendships: 105082\n",
      "Average degree: 53.03\n",
      "Network density: 0.0134\n",
      "Average shortest path length: 1.99\n",
      "Diameter: 2\n"
     ]
    }
   ],
   "source": [
    "# Network statistics\n",
    "print(\"Network Statistics:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total users: {processor.G.number_of_nodes()}\")\n",
    "print(f\"Total friendships: {processor.G.number_of_edges()}\")\n",
    "print(f\"Average degree: {sum(dict(processor.G.degree()).values()) / processor.G.number_of_nodes():.2f}\")\n",
    "print(f\"Network density: {nx.density(processor.G):.4f}\")\n",
    "\n",
    "# Check if graph is connected\n",
    "if nx.is_connected(processor.G):\n",
    "    print(f\"Average shortest path length: {nx.average_shortest_path_length(processor.G):.2f}\")\n",
    "    print(f\"Diameter: {nx.diameter(processor.G)}\")\n",
    "else:\n",
    "    print(\"Graph is not fully connected\")\n",
    "    components = list(nx.connected_components(processor.G))\n",
    "    print(f\"Number of components: {len(components)}\")\n",
    "    print(f\"Largest component size: {len(max(components, key=len))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Interactive Search Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network-Aware Search Interface\n",
      "==================================================\n",
      "Searching as user: 686\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter search query (or 'quit' to exit):  stanford\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 results for 'stanford':\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter search query (or 'quit' to exit):  sport\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 results for 'sport':\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter search query (or 'quit' to exit):  stanford\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 results for 'stanford':\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter search query (or 'quit' to exit):  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def interactive_search():\n",
    "    \"\"\"Interactive search session\"\"\"\n",
    "    print(\"Network-Aware Search Interface\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Searching as user: {searcher_id}\\n\")\n",
    "    \n",
    "    while True:\n",
    "        query = input(\"\\nEnter search query (or 'quit' to exit): \").strip()\n",
    "        \n",
    "        if query.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        if not query:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            results = search_engine.search(query, searcher_id, size=5)\n",
    "            \n",
    "            print(f\"\\nTop 5 results for '{query}':\")\n",
    "            print(\"-\"*50)\n",
    "            \n",
    "            for i, result in enumerate(results, 1):\n",
    "                print(f\"\\n{i}. User {result['user_id']} (Score: {result['scores']['final']:.2f})\")\n",
    "                print(f\"   Network: {result['network']['social_distance']} hops, \"\n",
    "                      f\"{result['network']['mutual_friends']} mutual friends\")\n",
    "                \n",
    "                if result['profile'].get('attributes'):\n",
    "                    attrs = result['profile']['attributes'][:3]\n",
    "                    print(f\"   Attributes: {', '.join(attrs)}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "# Uncomment to run interactive search\n",
    "interactive_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've built a network-aware search system that:\n",
    "\n",
    "1. **Loads social network data** from the Facebook dataset\n",
    "2. **Indexes user profiles** in Elasticsearch with attributes and circles\n",
    "3. **Computes network features** (social distance, mutual friends, shared circles)\n",
    "4. **Reranks search results** by combining text relevance with network proximity\n",
    "5. **Provides interpretable results** showing why users were ranked\n",
    "\n",
    "### Key Insights:\n",
    "\n",
    "- **Social distance** has exponential decay - users 1 hop away are much more relevant than 2 hops\n",
    "- **Mutual friends** provide trust signals\n",
    "- **Shared circles** indicate common interests/communities\n",
    "- Weight tuning lets you balance relevance vs. social proximity\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Add temporal features (recent interactions)\n",
    "2. Implement learning-to-rank with user feedback\n",
    "3. Add faceted search by circles/communities\n",
    "4. Scale to larger networks with approximate algorithms\n",
    "5. Build a web UI for easier interaction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
